#!/usr/bin/env bash

set -euo pipefail

VERSION="1.5.0"
FLAG_SERVE="false"
MAX_PROCESSES="32"; export MAX_PROCESSES

dir=$(mktemp -d); export dir

subs=(
  "memes"
)

# Logging utilities
function log::_timestamp() { date +'%Y-%m-%dT%H:%M:%S%z'; }; export -f log::_timestamp
function log::info() { echo "$(log::_timestamp) [INFO] $*" >&2; }; export -f log::info
function log::warn() { echo "$(log::_timestamp) [WARN] $*" >&2; }; export -f log::warn
function log::error() { echo "$(log::_timestamp) [ERROR] $*" >&2; }; export -f log::error

# Using the reddit api find the top posts and download the images into the directory.
function download_memes() {
  # Wget sometimes fails to download from some domains blocking scripting, this is fine and we should continue to process
  set +e

  log::info "Downloading memes from /r/${1}"
  
  wget -q -O - "https://reddit.com/r/${1}/top.json?t=day" \
    | jq '.data.children[].data.url' \
    | grep -E '(png|jpg|jpeg)' \
    | xargs -P "${MAX_PROCESSES}" wget -nc -q -P "${dir}"

  log::info "Finished downloading from /r/${1}"

  set -e
}; export -f download_memes

# Create an html page with all of the images
function build_html() {
  html_file="${dir}/index.html"
  log::info "exporting images to html file ${html_file}"

  echo '
  <style>
  img {
    max-width: 100%;
  }

  ul {
    padding: 0;
    display: flex;
    flex-direction: column;
    text-align: center;
  }

  li {
    list-style: none;
    padding: 10px;
  }
  </style>
  <ul>
  ' > "${html_file}"
  ls "${dir}" -t | grep -v html | xargs -I {} echo '<li><img src="{}" /></li>' >> "${html_file}"
  echo '</ul>' >> "${html_file}"

}

# Parse script arguments.
function parse_args() {
  while [ "$#" -gt 0 ]; do
    case "$1" in
      -v | --version) echo "${VERSION}"; exit 0 ;;
      -s | --serve) FLAG_SERVE="true" ;;
      --subs) IFS=',' read -ra subs <<< "${2}"; shift ;;
      *) dir="${1}";;
    esac
    shift
  done
}

# Script entrypoint.
function main() {
  parse_args "$@"

  log::info "Downloading to ${dir}"
  log::info "Collecting content from these subs [$(printf '%s,' "${subs[@]}")]"

  printf '%s\0' "${subs[@]}" \
    | xargs -P "${MAX_PROCESSES}" -n 1 -0 -I '{}' bash -c 'download_memes "{}"'

  # Assemble an html file that describes the directory
  build_html

  echo "${dir}"

  if [[ "${FLAG_SERVE}" = "true" ]]; then
    # Use the built in python http server
    python3 -m http.server --directory "${dir}"
  fi
}
main "$@"
